---
title: "p8105_hw2_cac2225"
author: "Courtney Chan"
date: "October 4, 2018"
output: github_document
---
#Problem 1 NYC Transit Data

First step is to save the relevant dataset to the data subdirectory folder, under the working directory. The tidyverse and dplry packages are loaded. The data is loaded using a relative path to the subdirectory, with the function readr, and given a name, "nyc_subway_data".

```{r loading library tidyverse}
library(tidyverse)
library(dplyr)
library(magrittr)
library(ggplot2) 

nyc_subway_data = read_csv(file = "./subdirectory_HW2data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv")
```

Names of the columns are cleaned using janitor::clean_names, converting names to lower snake case.

```{r data cleaning - clean column names}
names(nyc_subway_data)

nyc_subway_data = janitor::clean_names(nyc_subway_data)
names(nyc_subway_data)
```

Preliminarily viewing dataset, the first few rows, last few rows, summary statistics which provide a general overview of whether there is missing column names, data etc.

```{r looking at data}
nyc_subway_data

tail(nyc_subway_data, 5)

skimr::skim(nyc_subway_data)
```

It seems that dataset appears to have all necessary column names, so moving onto the next step of selecting certain columns.

```{r selecting certain columns}
select(nyc_subway_data, line, station_name, station_latitude, station_longitude, route1:route11, entry, vending, entrance_type, ada)
```

To recode the variable entry.

```{r convert entry variable}
nyc_subway_data = mutate(nyc_subway_data, entry = ifelse(entry == "YES", "True", "False"))
```

The dataset nyc_subway_data contains variables that describe the subway lines available in New York City, via whether the line was BMT/IND operated and its line catagorization, where its stations are located via latitude/longitude, street location, availability of entry and exit, ada compliant, availability of vending and staffing, and the names of the stations. My cleanupu steps involved cleaning the column names to lower snake case, ensuring that there were no column names missing, as well as a brief overview of the data. I selected certain columns to work with and recoded the variable "entry".

The definition of tidy data involve column names being variables themselves, rows are observations and every value has its own cell. No, the data is not yet tidy, as each route number value has its own column. In order to make this data tidy, two columns should be made, one column for variable "route_number" and one column for a corresponding "route_train" for the trains that serve each route.

To determine how many distinct stations there are, as defined by unique combinations of station name and line, use the distinct function.

```{r finding distinct by station and line stations}
distinct(nyc_subway_data, station_name, line)
```

Filtering by line and station name, there are 465 distinct stations.

```{r  distinct stations ADA compliant}
filter(nyc_subway_data, ada == "TRUE") %>%
  distinct(.data = ., station_name, line)
```

Of the distinct stations, 84 are ADA compliant.

```{r number of stations without vending}
no_vending = filter(nyc_subway_data, vending == "NO")
```
183 stations do not have vending

```{r number of stations with entrance}
no_vending_entrance = filter(nyc_subway_data, entry == "True", vending == "NO")
```
69 stations do not have vending and allow entrance. Thus 69/183 stations without vending allow entrance.

```{r create route_name and route_number}
tidy_nyc_subway_data = gather(nyc_subway_data, key = route_number, value = route_name, route1:route11)
```

Using gather route variables have been combined into route_number and route_name.

```{r distinct A stations}
filter(tidy_nyc_subway_data, route_name == "A") %>% distinct(.data = ., station_name, line)
```

60 subway distinct subway stations serve the A train.

```{r distinct ADA A stations}
filter(tidy_nyc_subway_data, route_name == "A", ada == "TRUE") %>% 
  distinct(.data = ., station_name, line)
```

17 distinct stations serve the A and are ADA compliant

The dimensions of the final dataset is `r dim(tidy_nyc_subway_data)`.

#Problem 2 Mr. Trash Wheel

## Mr. Trash wheel data

To load xlsx data, the library package readxl must be loaded. Then read_excel function is executed. Specify that column names are already included, certain range of data and that data is on the first sheet of the excel file.

```{r Loading Trash Wheel dataset}
library(readxl)

trash_data = read_excel("./subdirectory_HW2data/HealthyHarborWaterWheelTotals2018-7-28.xlsx", sheet = 1, col_names = TRUE, range = "A2:N336")
```

```{r cleaning up the trash...data names}
trash_data = 
  janitor::clean_names(trash_data) %>%  filter(dumpster != "NA") %>% 
  mutate(sports_balls = round(as.integer(sports_balls)),0)
 
```

Cleaning up the names with the janitor::clean_names function. Removed rows without dumpster-specific data. Variable sports_balls is an integer and rounded to the nearest integer.

## Precipitation data 2016 and 2017

```{r reading 2016 precipitation data}
precip_2016 = read_excel("./subdirectory_HW2data/HealthyHarborWaterWheelTotals2018-7-28.xlsx", sheet = 5, col_names = TRUE, range = "A2:B14")

```

```{r reading 2017 precipitation data}
precip_2017 = read_excel("./subdirectory_HW2data/HealthyHarborWaterWheelTotals2018-7-28.xlsx", sheet = 4, col_names = TRUE, range = "A2:B14")
```

```{r cleaning precip_2016 and precip_2017}
precip_2016 = janitor::clean_names(precip_2016) %>% mutate(year = 2016)

precip_2017 = janitor::clean_names(precip_2017) %>% mutate(year = 2017) 

precip_2016_2017 = 
  full_join(precip_2016, precip_2017)
       
precip_2016_2017 = 
  mutate(precip_2016_2017, month = as.character(factor(month, levels = 1:12, labels = month.name)))

```
The number of observations in the final Mr. Trash dataset is `r nrow(trash_data)`.
The number of observations in the final precip_2016_2017 dataset is `r nrow(precip_2016_2017)`.
Key variables of the Mr. Trashy Wheel data set would be year, date and weight_tons of trash collected since these tell you about the trends on when the most trash overall was collected.
Key variables of the final precip_2016_2017 dataset would be year and precipitation since it's important to pinpoint when the most precipitation occurred.
The total precipitation in 2017 was `r sum(precip_2016_2017$total)`.
The median number of sports balls in a dumpster in 2016 was `r median(trash_data$sports_balls)`.

#Problem 3

Load the data from the source.
```{r loading the data}

#install.packages("devtools")
#devtools::install_github("p8105/p8105.datasets")

library(p8105.datasets)
data(brfss_smart2010)

library(dplyr)
library(tidyverse)

```

Data is first cleaned and filtered

```{r clean and format the data}
brfss_smart2010_clean = janitor::clean_names(brfss_smart2010) %>% 
  filter(topic == "Overall Health")
```

Desired variables are selected, response variable is spread out and proportion variable is created to represent the proportion of Excellent/Good responses.

```{r select and create variables}
brfss_smart2010_clean = select(brfss_smart2010_clean, year, locationabbr, locationdesc, response, data_value) %>% spread(key = response, value = data_value) %>% mutate(proportion = Excellent/Good)
```

```{rr finding distinct stations}
distinct(brfss_smart2010_clean, locationdesc)
length(unique(brfss_smart2010_clean$locationabbr))
tail(names(sort(table(brfss_smart2010_clean$locationabbr))),1)

brfss_smart2010_clean_median = filter(brfss_smart2010_clean, year == 2002)

median(brfss_smart2010_clean_median$Excellent,na.rm = TRUE)
```

There are 404 unique locations in the dataset. Every state and D.C. is represented. The state that is observed the most is NJ. In 2002, the median of the "Excellent" response value is 23.6.

```{r filter and plots}
filter(brfss_smart2010_clean, year == 2002) %>% 
ggplot(aes(x = Excellent)) + geom_histogram()
```

```{r creating scatter plot data}
brfss_smart2010_scatter = brfss_smart2010_clean %>%  filter(brfss_smart2010_clean$locationdesc == "NY - New York County" | brfss_smart2010_clean$locationdesc == "NY - Queens County")
```

```{r creating scatterplot}
ggplot(brfss_smart2010_scatter, aes(x = year, y = Excellent)) + 
  geom_point(aes(color = locationdesc), alpha = .5)
```

